{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c9e7b10d2bfe67d4",
      "metadata": {
        "collapsed": false,
        "id": "c9e7b10d2bfe67d4"
      },
      "source": [
        "# Quick Start\n",
        "\n",
        "[Run this tutorial in Google Colab](https://colab.research.google.com/github/sony/model_optimization/blob/quickstart-table/tutorials/notebooks/example_quick_start_torchvision.ipynb)\n",
        "\n",
        "Steps:\n",
        "* **Setup the environment**: install MCT and add tutorials to PYTHONPATH\n",
        "* **Download and organize the imagenet dataset**\n",
        "* **Run quick_start on your model**\n",
        "\n",
        "**Note**: The following code should be run on a GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e81b09e6d30873",
      "metadata": {
        "collapsed": false,
        "id": "d0e81b09e6d30873"
      },
      "source": [
        "## Setup\n",
        "\n",
        "install and import relevant packages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eda6ab0d8f0b6b56",
      "metadata": {
        "collapsed": false,
        "id": "eda6ab0d8f0b6b56"
      },
      "source": [
        "In order to convert the PyTorch model, you'll need to use the conversion code in the [MCT tutorials folder](https://github.com/sony/model_optimization/tree/main/tutorials), so we'll clone the MCT repository to a local folder and only use that code. The installed MCT package will be used for quantization.\n",
        "  **It's important to note that we use the most up-to-date MCT code available.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca9a743c0e7ba067",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca9a743c0e7ba067",
        "outputId": "10c7246b-8b31-4c44-9a45-04d4d3a2958b"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/sony/model_optimization.git local_mct\n",
        "!pip install -r /content/local_mct/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "PfJ3_AyieBL0",
      "metadata": {
        "id": "PfJ3_AyieBL0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] = '/content/local_mct/'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ufTwrlH-eCyB",
      "metadata": {
        "id": "ufTwrlH-eCyB"
      },
      "source": [
        "## Dataset\n",
        "Download the imagenet validation dataset.\n",
        "\n",
        "Use torchvision.datasets.ImageNet to create the dataset in the correct structure.\n",
        "\n",
        "**Note**: We use validation for time convinience since the training split is too big. To measure accurate validation results, the validation samples should only be used for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cj6WQGrLvkvx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj6WQGrLvkvx",
        "outputId": "46efb6a0-abe3-48d9-ce89-6890a566e6de"
      },
      "outputs": [],
      "source": [
        "!mkdir imagenet\n",
        "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz\n",
        "!mv ILSVRC2012_devkit_t12.tar.gz imagenet/\n",
        "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
        "!mv ILSVRC2012_img_val.tar imagenet/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "coxDAP4Av3ol",
      "metadata": {
        "id": "coxDAP4Av3ol"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "ds = torchvision.datasets.ImageNet(root='/content/imagenet', split='val')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gY2UsnzOfjtk",
      "metadata": {
        "id": "gY2UsnzOfjtk"
      },
      "source": [
        "## Run Quick Start script on our model of choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZJ8CR1FQRwg2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ8CR1FQRwg2",
        "outputId": "607f95e7-8c80-408f-ebe8-ace70f999e3e"
      },
      "outputs": [],
      "source": [
        "!python /content/local_mct/tutorials/quick_start/main.py --model_name mobilenet_v2 --model_library torchvision --validation_dataset_folder /content/imagenet/val --representative_dataset_folder /content/imagenet/val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d80935",
      "metadata": {},
      "source": [
        "\n",
        "Copyright 2024 Sony Semiconductor Israel, Inc. All rights reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
